# Как происходит компиляция c++

В машинный код приложения на *C* и *C++* переводятся один раз - перед запуском программы.
Этот процесс и называется **компиляцией**. Компилятор переводит исходный код, написанный на одном из языков программирования,
в семантически эквивалентный объектный код.

## Процесс компиляции

Такое преобразование происходит постепенно:

![](https://raw.githubusercontent.com/Fawentus/fl-2021-hse-win/proj/schemes/compilation.jpg)

**Лексический анализ** - это анализ, при котором происходит считывания потока символов исходной программы
слева направо сверху вниз и группировка их в токены. Они представляют собой совокупность последовательностей символов с определенным значением.

**Синтаксический анализ** - это анализ, при котором токены иерархически группируются во вложенные конструкции. 
Обычно такие грамматически фразы представляются в виде дерева.

**Семантический анализ** - это анализ наличия семантических ошибок и накапливание информации о типах. 
При таком анализе используются иерархические структуры, полученные во время синтаксического анализа для идентификации 
операторов и операндов выражений и инструкций. На этом этапе также происходит проверка на соответствие типов.

Но на деле всё немного сложнее.
Можно процесс компиляции разделить на три основных этапа, которые будут включать в себя приведенные выше фазы:

1) Front End
2) Middle End
3) Back End

Поговорим о них подробнее.

### Front End

На этом этапе из кода удаляются все незначащие символы (в случае *C++* это, к примеру, лишние пробелы), 
комментарии и другое форматирование. Также добавляются в код хэдеры `#include`, заменяются макросы `#define`
их значениями, выбирают нужные куски кода в соответствии с условиями `#if`, `#ifdef` и `#ifndef`.
Хэдеры, включенные в программу с помощью директивы `#include`, добавляются рекурсивно. Именно поэтому, нужно использовать:

```c++
#ifndef NAME
#define NAME

#endif
```
или директиву, не включенную в стандарт, но широко распространенную:

```c++
#pragma once
```
Всё это называют **предпроцессингом**.

Затем производится проверка синтаксической структуры программы, диагностика на соответствие языку, 
создание внутренних структур для типов данных и переменных, объявленных в программе (таблица символов). 
Также происходит отладка информации, такой как имена 
файлов и номера строк. Это может пригодиться, к примеру, для вывода сообщений об ошибках.

Исходная программа преобразуется в более лаконичную форму, называемую **Intermediate Representation** (IR).
Для этого создается структура данных - **Abstract Syntax Trees** (AST), которая представляет каждый оператор 
в некоторой заданной иерархии.

Например, для `x = 31 + y \ 2` AST выглядит так: 

![](https://raw.githubusercontent.com/Fawentus/fl-2021-hse-win/proj/schemes/AST.jpg)

Более сложный пример:

```c++
template<bool> struct a_t;

template<> struct a_t<true> {
    template<int> struct b {};
};

template<> struct a_t<false> {
   enum { b };
};

typedef a_t<sizeof(void*)==sizeof(int)> a;

enum { c, d };
int main() {
    a::b<c>d; // declaration or expression?
}
```

Дерево для него будет выглядеть так:

![](https://i.stack.imgur.com/Pdbnz.png)

Этот пример был взят из [ответа](https://stackoverflow.com/questions/17388771/get-human-readable-ast-from-c-code/17393852#17393852) 
на stackoverflow. Из этого и других ответов в этой же ветке можно понять, как 
самому получить AST из кода *C++* для лучшего понимания.

### Middle End

На этом этапе есть две основные цели: оптимизация времени работы и оптимизация занимаемой памяти.
Какие оптимизации существуют:

1) Упрощения выражений. Для этого используются ассоциативность, коммутативность, дистрибутивность
и другие свойства операторов. Например, `x + 6 - x` преобразуется в `6`
2) Вычисление констант. Например, `x = 4 + 5 - 3` можно заменить на `x = 6`
3) Устранение избыточности. Существует несколько методов, наиболее распространенные из них:
    * Если выражение вычисляется более одного раза и при этом его операнды 
 не изменяются, то повторные вычисления заменяются результатом вычисления, полученным в первый раз
    * Вычисления внутри циклов, которые дают один и тот же результат для каждой итерации, 
 выносятся за пределы цикла. Например, в этом случае:
      
      ```
      k = 10;
      b = 6;
      while (k > 0) {
          a = b + 17;
          k -= a;
      }
      return k;
      ```
      
      за пределы цикла можно вынести `a = b + 3;`. В результате получим:
      
      ```
      k = 10;
      b = 6;
      a = b + 17;
      while (k > 0) {
          k -= a;
      }
      return k;
      ```
      
      Но эта оптимизация работает только с простыми случаями, даже самый хороший компилятор не всегда может
      обработать что-то более сложное. Например, оптимизатор не смог помочь создателям игры GTA Online,
      которые (по мнению [T0ST](https://github.com/tostercx)) использовали в цикле функцию `sscanf`, в свою очередь вызывающую `strlen` для неизменяемого
      файла. В том числе и из-за этого время загрузки игры было достаточно большим 
      ([ссылка на статью](https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/))
 
 4) Частичное устранение избыточности. Оно применяет предыдущие методы не для выражения целиком,
 а для некоторой его части
 
 ### Back End
 
 На этом этапе
 компилятор должен обладать подробными знаниями об оборудовании, на котором будет
 выполняться программа. Промежуточное представление программы
 преобразуется в форму, напоминающую машинный язык. В этой форме можно применять преобразования, 
 использующие преимущества целевой архитектуры. Например:

1) Распределение регистров. Максимизируется количество переменных, которые назначаются регистрам,
работающим более быстро
2) Планирование кода. Используются преимущества процессора для перестановки инструкций
таким образом, чтобы несколько инструкций находились на стадии выполнения одновременно.
Из-за этой оптимизации код может выполняться не так, как он задумывался. К примеру, при использовании
потоков нам может быть важен конкретный порядок выполнения действий. При этой оптимизации он мог
измениться. В том числе и для того, чтобы избежать неожиданного поведения программы в этом случае,
нужно использовать `mutex`. Также может быть интересно почитать [это](https://stackoverflow.com/questions/38891137/is-gcc-reordering-local-variables-at-compilation-time)
3) Peephole-оптимизаций, которые могли быть уже частично произведены на прошлом этапе. 
Подробнее о них можно почитать [здесь](https://habr.com/ru/post/458150/)

Даже после окончательной генерации кода полученный код, как правило, не готов к запуску.
Некоторые компиляторы, в том числе и *GCC*, генерируют ассемблерный код, который затем подается 
в ассемблер для генерации объектного кода. Это называют **ассемблирование**.
После создания объектного кода происходит **линковка** - сбор всех объектных файлов
и библиотек, необходимых для создания окончательного исполняемого файла.
В конце выполняется **загрузка**. При этом происходит загрузка программы в память. На данной 
стадии также возможна подгрузка динамических библиотек (в Windows они имеют расширение `.dll` 
(сокращение от dynamic link library), в Linux `.so` (сокращение от shared object)). Динамические библиотеки не являются частью
исполняемого файла. Разные программы могут совместно использовать одну копию динамической библиотеки, 
что значительно экономит используемое пространство. А еще её можно обновлять без необходимости 
перекомпиляции всех исполняемых файлов, которые её используют.

## Внутренняя организация GCC

*GCC* разработан вокруг двух разных IR:
1) Деревья, которые по сути являются AST
2) **Register Transfer Language** (RTL). Оно используется *GCC* для оптимизации и генерации кода

Процесс компиляции в *GCC* выглядит так:

![](https://raw.githubusercontent.com/Fawentus/fl-2021-hse-win/proj/schemes/gcc.jpg)

Изначально создается AST. Для каждого языка программирование это происходит по-своему.
После этого происходит преобразование в **GENERIC**.

### GENERIC

Чтобы иметь возможность использовать одни и те же механизмы при компиляции программ,
написанных на разных языках, и было введено представление GENERIC. Оно является некоторым 
обобщением всех существующих древовидных представлений в GCC. На официальном сайте GCC
можно найти [некоторые подробности о GENERIC](https://gcc.gnu.org/onlinedocs/gccint/GENERIC.html).

### GIMPLE

Преобразование в GENERIC удаляет все языковые зависимости. Тем не менее 
GENERIC деревья по-прежнему являются структурно сложными. Представление, называемое **GIMPLE**, 
лексически идентично GENERIC, но оно накладывает некоторые ограничения. Например:

1) Ни одно выражение не может содержать более 3 операндов 
2) Аргументы функции могут быть только переменными (вызовы функций не могут быть 
вложенными)
3) Предикат операторов (таких, как, к примеру, if, while) может содержать только одно сравнение,
причем в него могут входить только переменные

Процесс преобразования GENERIC в GIMPLE, называется **gimplifier**.
Представление GIMPLE создается путем разбиения GENERIC выражений на кортежи, не более чем 
из 3 операндов (за некоторыми исключениями, такими как, к примеру, вызовы функций).
Разбитие на кортежи происходит рекурсивно. Такие рекурсивные синтаксические анализаторы спуска
являются рукописными. Это сделано по нескольким причинам:

1) Производительность. Рукописность парсера открывает большую свободу для оптимизаций, всё
находится под контролем разработчика. Также быстрый синтаксического анализатор можно 
использовать и в других инструментах разработки, где такие синтаксические анализаторы обычно
не используются. Например, для подсветки синтаксиса и подсказок при написании кода в среде IDE
2) Поиск ошибок: из-за полного контроля работы, проще обрабатывать разные случаи, находить 
и предлагать варианты исправления ошибок, [пример](http://clang.llvm.org/features.html#expressivediags)
3) Простота: синтаксические анализаторы рекурсивного спуска относительно легко писать, понимать и отлаживать.
Так как исходный код является открытым, эта действительно важно для расширения/улучшения анализатора
4) Некоторые исторические причины

Больше контекста можно найти [здесь](https://stackoverflow.com/questions/6319086/are-gcc-and-clang-parsers-really-handwritten).
Также [здесь](https://gcc.gnu.org/wiki/New_C_Parser) можно найти ссылки на описание изменений,
которые были добавлены в парсеры разных версий.

О GIMPLE подробнее можно почитать на [соответствующей странице](https://gcc.gnu.org/onlinedocs/gccint/GIMPLE.html#GIMPLE)
официального сайта. Там есть некоторые примеры, приведена иерархия операторов, 
можно найти информацию об обработке исключений и еще много всего интересного.
Ещё может быть полезным почитать [это](https://gcc.gnu.org/onlinedocs/gccint/Parsing-pass.html).

Попробуем на примере понять, чем GENERIC отличается от GIMPLE.

### Различия между GENERIC и GIMPLE

``` c++
// GENERIC

if (foo (a + b, c)) {
    c = b++ / a;
    
}
return c;
```

``` c++
// GIMPLE

t1 = a + b;
t2 = foo (t1, c);
if (t2 != 0) {
    t3 = b;
    b = b + 1;
    c = t3 / a;
}
return c;
```

Как можно заметить из примера, чтобы при вызове функции `foo` аргументом не было арифмитическое выражение,
результат суммы значений переменных `a` и `b` был сохранён в переменную `t1`. Аналогичным образом
возвращаемое значение функции `foo` было сохранено в переменную `t2`, чтобы избежать вложенности.
Также было разбито выражение `c = b++ / a;`

### Tree Static single assignment (SSA) Optimizer

Главная идея представления **SSA** заключается в управлении версиями переменных. 
Форма SSA требует, чтобы каждой переменной присваивалось значение только один раз. Поэтому 
каждый раз, когда переменной присваивается новое значение, компилятор создает её новую
версию. Когда эта переменная используется, компилятор ищет её последнюю версию,
которую и будет использовать. Такое представление существует только для компилятора, 
оно никак не отображается в сгенерированном коде.

К примеру:

``` c++
// GIMPLE

a = 3;
b = 9;
c = a + b;
a = b + 1;
d = a + c;
return d;
```

``` c++
// SAA

a_1 = 3;
b_2 = 9;
c_3 = a_1 + b_2;
a_4 = b_2 + 1;
d_5 = a_4 + c_3;
return d_5;
```

Почему это полезно? Рассмотрим оптимизацию вычисление констант, о которой уже говорили.
Поскольку программа находится в форме SSA, все переменные имеют номера версий. Компилятор может
просто создавать массивы, индексированные по номеру версии, чтобы отслеживать значения,
которые не изменяются. Предположим, у нас есть массив `CST` для этой цели. В примере
рассмотренном выше, `CST[1] = 3` и `CST[2] = 9`. Таким 
образом, когда компилятор проверяет инструкцию в строке `c_3 = a_1 + b_2`, так как `CST[3] = 12`, он может 
сделать вывод , что `c_3` должно быть всегда `12`. После того как все инструкции
будут рассмотрены, получаем:

``` c++
// SAA

a_1 = 3;
b_2 = 9;
c_3 = 12;
a_4 = 10;
d_5 = 22;
return 22;
```

Мы получили, что ни одно из этих присвоений не является действительно полезным. Эта 
программа просто вычисляет и возвращает значение `22`, поэтому можно попробовать соптимизиравать
вызов этой функции (конечно, учитывается, что эти переменные могут быть, к примеру, глобальными,
из-за чего будет нельзя просто выкинуть всё тело функции, заменив ее вызов на значение `22`).

Что же происходит, когда невозможно определить, какова последняя версия переменной? 
Например, в следующей программе компилятору может быть
невозможно определить, какая ветвь условного оператора будет выполнена:

``` c++
// GIMPLE

x = foo();
if (x > 10) {
    a = 92;
}
else {
    a = 23;
}
return a;
```

Чтобы устранить неоднозначность, компилятор создает ещё одну, третью версию для переменной `a`.
Эта версия будет слиянием двух конфликтующих версий. Такая операция слияния известна как **функция PHI**:

``` c++
// SAA

x_1 = foo();
if (x_1 > 10) {
    a_2 = 92;
}
else {
    a_3 = 23;
}
a_4 = PHI(a_2, a_3);
return a_4;
```

В этом случае мы уже не сможем однозначно сказать, какое значение будет возвращено.
Значит не можем соптимизировать эту часть так, как могли бы в прошлом примере.

### Register transfer language (RTL)

Большая часть работы по оптимизации выполняется именно в RTL. Его можно рассматривать как язык 
ассемблера для машины с бесконечным числом регистров. Когда *GCC* был первоначально реализован, он почти сразу
создавал RTL, именно поэтому большая часть компилятора и сейчас реализована вокруг него.
RTL - это низкоуровневое представление, поэтому он хорошо подходит для таких оптимизаций, 
как [распределение регистров](https://en.wikipedia.org/wiki/Register_allocation), 
оптимизация [delay slot](https://en.wikipedia.org/wiki/Delay_slot) 
([тут](https://stackoverflow.com/questions/15375084/what-is-the-point-of-delay-slots) можно узнать некоторые подробности, для чего она нужна),
[peephole-оптимизаций](https://en.wikipedia.org/wiki/Peephole_optimization) (о них упоминалось в 
части про этап Back End) и т.д..

Больше полезной и интересной информации можно найти на 
[странице об RTL](https://gcc.gnu.org/onlinedocs/gccint/RTL.html) на официальном сайте.

## Ещё немного об оптимизациях

Хочется заметить, что разные версии компилятора могут оптимизировать программу по-разному. 
Причём времена работы программы могут отличаться весьма существенно. Например, одно и то же решение 
задачи, собранное GNU C++17 7.2.0 (msys2 mingw-w64-x86_64) inc (inc означает, что подключение 
библиотеки [optimization.h](https://acm.math.spbu.ru/~sk1/algo/lib/optimization.h.html) будет корректным)
получает Time Limit в тестирующей системе, в то время, как решение, собранное
GNU C++14 5.1.0 (TDM-GCC-64) inc получает OK.

![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/af85962d-1e18-4ddb-bc8e-6bf34344d3a4/SmartSelect_20211005-172654_Samsung_Internet.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211017%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211017T074808Z&X-Amz-Expires=86400&X-Amz-Signature=ebdd0aae5638eb49622971550dc9190a1e2cf2b415e50ee6a0812a3dd45c9913&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22SmartSelect_20211005-172654_Samsung%2520Internet.jpg%22)

# Особенности синтаксиса с++

## Lexer hack

Как уже упоминалось ранее, на этапе компиляции происходит построение таблицы символов.
Для чего же она нужна? В языках *C* и *C++* последовательности символов классифицируются в качестве
имени переменной или имени типа в зависимости от контекста. Именно поэтому для этих языков
невозможно использование контекстно-свободный лексер.

Самый простой и наиболее распространённый пример:

```c++
(A)*B
```

В данном случае можно интерпретировать это по-разному: это может быть умножением двух переменных
или приведение разыменованного `B` к типу `A`.

Использование таблицы символов решает эту проблему. [Здесь](https://en.cppreference.com/w/cpp/language/lookup)
можно почитать про процедуру поиска имени.

## Dangling else

Ещё одна распространённая проблема это dangling else. При использовании оператора `if` наличие 
ветки `else` необязательно. Из-за этого могут возникнуть трудности  при интерпретации части кода
с вложенными `if`-ами. В языках *C* и *C++* ветку `else` принято относить к ближайшему `if`, если 
это не определено однозначно.

## Приоритеты операторов

Все стандартные операторы имеют приоритеты. Компилятор использует таблицу приоритетов для определения
порядка вычисления. В языках *C* и *C++* нет возможности менять приоритет операторов,
как это можно, например, в Haskell. При перегрузке операторов, приоритеты останутся прежними.
Поэтому, к примеру, для таких выражений:

```c++
a = 3 * 9 + 6;
b = ++a*3;
```
интерпретация будет в любом случае однозначной.

Есть некоторые операторы, перегрузка которых запрещена, например оператор `.`. Также запрещено
определять свои собственные операторы, например, такой код не является корректным:

```c++
#include <iostream>

struct Integer {
	int value;

	Integer() : value(0) {}
	Integer(int value_) : value(value_) {}
};

const Integer operator+++(const Integer& left, const Integer& right) {
	return Integer(left.value + right.value);
}

void print(Integer x) {
	std::cout << x.value;
}

int main() {
	Integer a(3), b(9);
	print(a +++ b);
}
```

В данном случае для типа `Integer` можно было бы переопределить оператор `+`, такая реализация
является допустимой.

В свою очередь связывание составных операторов определено не через таблицу, а через грамматику языка.
Из-за этого могут возникать двусмысленные интерпретации. Хорошим примером служит только что рассмотренная 
проблема с dangling else. Еще одним пример - это синтаксис оператора `?:`. В языке *C* он таков:

```c
logical-OR-expression ? expression : conditional-expression
```

а в *C++* таков:

```c++
logical-OR-expression ? expression : assignment-expression
```

Таким образом выражение:

```c++
e = a < d ? a++ : a = d
```

в разных языках будет интерпретировано по-разному. В *C* выражение синтаксически некорректно, (результат условного
оператора не может быть lvalue). В *C++* выражение будет корректным.

# Время компиляции

Если интересно, можно попробовать [самому засечь](https://stackoverflow.com/questions/3025443/how-to-calculate-gcc-compilation-time)
время компиляции программы.
[Здесь](https://github.com/Fawentus/fl-2021-hse-win/blob/proj/gcc_compilation_time/my_ex.md) можно посмотреть на анализ времени компиляции разных программ, который мне удалось получить.
А [здесь](https://github.com/Fawentus/fl-2021-hse-win/blob/proj/gcc_compilation_time/ex.md) - анализ времени компиляции других пользователей.

Чтобы было немного понятнее:

`usr` — user time, время в коде компилятора

`sys` — system time, время в ядре (например, ввод-вывод)

`wall` — wall clock time, время "по часам на стене", с учётом планировщика, лагов системы и вообще всего-всего

Этих данных не так много, чтобы делать конкретные выводы о процентном соотношении времени работы разных этапов
компиляции. Но даже не обладая специальными знаниями и не производя расчетов можно заметить, что на парсинг
уходит приличная часть времени от всей компиляции. Утверждение, что *GCC* проводит чуть ли не 40% времени за синтаксическим анализом,
не является беспочвенным. Опираясь на полученные результаты, смею предположить, что это действительно так.

К сожалению, найти достоверные результаты времени работы на разных этапах компиляции с большим числом 
анализируемых данных мне не удалось. Но из переписки официальных представителей *Apple* и создателей *GCC* можно заключить, 
что синтаксический анализатор действительно является одной из самых медленных частей компиляции. 
Эту переписку можно найти в [архиве писем](https://gcc.gnu.org/legacy-ml/gcc/2000-08/index.html#00515) gcc@gcc.gnu.org по теме:
`PCH, and more generally C++ parser performance`. Но нужно учитывать, что это довольно старая переписка, однако,
думаю, она всё же может дать некое представление о затрате времени на конкретные части компиляции.

Также может быть интересным почитать [этот](https://stackoverflow.com/questions/37260097/stdarray-with-aggregate-initialization-on-g-generates-huge-code) 
и [этот](https://stackoverflow.com/questions/13898985/why-does-compiling-over-100-000-lines-of-stdvectorpush-back-take-a-long-time) вопросы
на stackoverflow и ответы на них. Они содержат примеры слишком медленной компиляции и компиляции, при которой
генерируется код, занимаемый достаточно большой объем памяти.

# Источники

## Ссылки, которые были указаны в тексте

1) [Статья о поиске недочетов в коде игры GTA Online](https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/)
2) [Peephole микрооптимизации](https://habr.com/ru/post/458150/)
3) [Ещё peephole-оптимизации](https://en.wikipedia.org/wiki/Peephole_optimization)
4) [Некоторые подробности о GENERIC](https://gcc.gnu.org/onlinedocs/gccint/GENERIC.html)
5) [Создание понятных и полезных сообщений об ошибках и предупреждений](http://clang.llvm.org/features.html#expressivediags)
6) [Описание изменений, добавленных в парсеры разных версий](https://gcc.gnu.org/wiki/New_C_Parser)
7) [Некоторые подробности о GIMPLE](https://gcc.gnu.org/onlinedocs/gccint/GIMPLE.html)
8) [Parsing pass](https://gcc.gnu.org/onlinedocs/gccint/Parsing-pass.html)
9) [Распределение регистров](https://en.wikipedia.org/wiki/Register_allocation)
10) [Delay slot](https://en.wikipedia.org/wiki/Delay_slot)
11) [RTL](https://gcc.gnu.org/onlinedocs/gccint/RTL.html)
12) [Name lookup](https://en.cppreference.com/w/cpp/language/lookup)
13) [Архив писем разработчиков GCC](https://gcc.gnu.org/legacy-ml/gcc/2000-08/index.html#00515)

### Вопросы на stackoverflow

1) [Получение читаемого AST из кода c++](https://stackoverflow.com/questions/17388771/get-human-readable-ast-from-c-code)
2) [Изменяет ли gcc порядок локальных переменных во время компиляции](https://stackoverflow.com/questions/38891137/is-gcc-reordering-local-variables-at-compilation-time)
3) [Действительно ли парсеры GCC и Clang написаны вручную](https://stackoverflow.com/questions/6319086/are-gcc-and-clang-parsers-really-handwritten)
4) [Смысл delay slots](https://stackoverflow.com/questions/15375084/what-is-the-point-of-delay-slots)
5) [Как узнать время компиляции](https://stackoverflow.com/questions/3025443/how-to-calculate-gcc-compilation-time)
6) [g++ генерирует ограммный код при aggregate initialization std::array](https://stackoverflow.com/questions/37260097/stdarray-with-aggregate-initialization-on-g-generates-huge-code)
7) [Компиляция более 100 000 строк std::vector::push_back](https://stackoverflow.com/questions/13898985/why-does-compiling-over-100-000-lines-of-stdvectorpush-back-take-a-long-time)

## Материалы, которые также были использованы в работе

1) [Официальный сайт GNU Compiler Collection](https://gcc.gnu.org)
2) [Исходники gcc для чтения](https://gcc.gnu.org/git.html), также можно посмотреть 
[здесь](https://github.com/gcc-mirror/gcc)
3) [Процесс компиляции программ на C++](https://habr.com/ru/post/478124/)
4) [Статья Diego Novillo](https://web.archive.org/web/20090401215553/http://www.redhat.com/magazine/002dec04/features/gcc/)
5) [Страница в wikipedia об IR](https://en.wikipedia.org/wiki/Intermediate_representation)
6) ["A Simple Graph-Based Intermediate Representation" by Cliff Click and Michael Paleczny](https://www.oracle.com/technetwork/java/javase/tech/c2-ir95-150110.pdf)
7) [Страница в wikipedia об SSA](https://en.wikipedia.org/wiki/Static_single_assignment_form)
8) [Статья про использование PHI в SSA](https://mapping-high-level-constructs-to-llvm-ir.readthedocs.io/en/latest/control-structures/ssa-phi.html)
9) [Немного о статических и динамических библиотеках](https://ravesli.com/staticheskie-i-dinamicheskie-biblioteki/#toc-0)
10) [Dangling else](https://www.gnu.org/software/bison/manual/html_node/Shift_002fReduce.html#Shift_002fReduce)
11) [Lexer hack](https://eli.thegreenplace.net/2007/11/24/the-context-sensitivity-of-cs-grammar/)
12) [Операторы на cppreference](https://en.cppreference.com/w/cpp/language/operators)
13) Перегрузка операторов: [статья](https://habr.com/ru/post/489666/) и [ещё одна статья](https://habr.com/ru/post/132014/)
14) [Почему компиляция такая долгая?](https://www.quora.com/Why-does-C++-take-so-long-to-compile)

### Вопросы на stackoverflow

1) [Значение merge, phi, effectphi and dead](https://stackoverflow.com/questions/57463700/meaning-of-merge-phi-effectphi-and-dead-in-v8-terminology)
на stackoverflow
2) [Это](https://stackoverflow.com/questions/26179500/how-do-i-download-gcc-source)
может помочь при скачивании исходников GCC
3) [Разница в AST и CST](https://stackoverflow.com/questions/1888854/what-is-the-difference-between-an-abstract-syntax-tree-and-a-concrete-syntax-tre)
